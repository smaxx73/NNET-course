{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Neural Network <div style=\"float:right\"><img class=\"w3-card-4\"\n",
    "     src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Logo_de_l%27acad%C3%A9mie_militaire_de_Saint-Cyr_Co%C3%ABtquidan.svg/1200px-Logo_de_l%27acad%C3%A9mie_militaire_de_Saint-Cyr_Co%C3%ABtquidan.svg.png\"\n",
    "                                                                          width=\"100px\" object-position=\"right top\"></div></h3>\n",
    "<div style=\"clear:both\"></div>\n",
    "\n",
    "<center>\n",
    "    <h1> Course 2 : Perceptron and theory  </h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 {\n",
       "  border: 1.5px solid #333;\n",
       "  padding: 8px 12px;\n",
       "  background-color:#f0cfc0;\n",
       "  position: static;\n",
       "}  \n",
       "h2 {\n",
       "  padding: 8px 12px;\n",
       "  background-color:#f0cfc0;\n",
       "  position: static;\n",
       "}   \n",
       "h3 {\n",
       "  padding: 4px 8px;\n",
       "  background-color:#f0cfc0;\n",
       "  position: static;\n",
       "}   \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "h1 {\n",
    "  border: 1.5px solid #333;\n",
    "  padding: 8px 12px;\n",
    "  background-color:#f0cfc0;\n",
    "  position: static;\n",
    "}  \n",
    "h2 {\n",
    "  padding: 8px 12px;\n",
    "  background-color:#f0cfc0;\n",
    "  position: static;\n",
    "}   \n",
    "h3 {\n",
    "  padding: 4px 8px;\n",
    "  background-color:#f0cfc0;\n",
    "  position: static;\n",
    "}   \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, IFrame\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear perceptron maps an input $x \\in \\mathbb{R}^n$ ($n$ values) to an output which can be a binary output $F(x) \\in \\{0,1\\}$ (1 value which is one or zero).\n",
    "\n",
    "This function is decomposed in two parts : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **linear function** : defined by $n$ weights $a_1,...,a_n$ :\n",
    "$$f(x) = a_1x_1 + a_2x_2 +...+ a_n x_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example : $n=2$, $(a_1,a_2) = (2,3)$ so that $f(x_1,x_2) = ...$ and $f(4,-1) = ...$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ... #n-vector x : x=(4,-1)\n",
    "a = ...   #n weights : (a_1,a_2) = (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,a):\n",
    "    return ...  #compute f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ellipsis\n"
     ]
    }
   ],
   "source": [
    "print(f(x,a))  #compute f(4,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **activation function** : it is a function $\\varphi \\colon \\mathbb{R} \\to \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example : Heaviside function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(y):\n",
    "    if y<0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H(f(x,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.linspace(-6,6,300)\n",
    "z=np.array(...)\n",
    "plt.plot(y, z, linewidth = 7.0, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is the number $H(f(x)) \\in \\{0,1\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example : ReLu function\n",
    "\n",
    "The Rectified Linear Unit function is the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(y):\n",
    "    if y < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.linspace(-6,6,300)\n",
    "z=np.array(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y, z, linewidth = 7.0, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example : Sigmoïd function\n",
    "\n",
    "The Sigmoïd function is the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(y):\n",
    "    return 1/(1+np.exp(-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.linspace(-6,6,300)\n",
    "z=np.array([sigmoid(t) for t in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y,z,linewidth=7.0,color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise : compute the derivative of the sigmoïd function and plot its graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear pereceptron is represented with a **neuron** as follows : <img src=\"Perceptron1.png\"> </img> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n=2$, $(a_1,a_2) = (2,3)$ so that $f(x_1,x_2) = 2x_1 + 3x_2$ and the activation function Heaviside : the output is\n",
    "\n",
    "- ... if ...\n",
    "- ... if ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame('https://www.geogebra.org/calculator/x63nersc?embed',900,400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "How to find a perceptron separating blue circles from red squares ?\n",
    "https://www.geogebra.org/calculator/zmyaznwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame('https://www.geogebra.org/calculator/zmyaznwf?embed',600,400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce a bias $a_0$ : this a $(n+1)$-th weight that defines an affine function $f(x_1,...,x_n) = a_1x_1+...+a_nx_n + a_0$. An affine perceptron is represented by a neuron as follows :\n",
    "<img src=\"Perceptron2.png\"> </img> \n",
    "\n",
    "#### Example : with 2 entries, an affine perceptron split a 2-dimensional space into 2 half planes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or, and, xor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computer science, a boolean variable is a variable $x$ that has 1 of 2 possible values (TRUE or FALSE). In a boolean algebra, if $x$ et $y$ are boolean, we can define ```x OR y```.\n",
    "\n",
    "We chose a graphic representation : TRUE is number 1, FALSE is number 0, ```x OR y``` is a point with $(x,y)$ coordinates in plane. This point is a red square if ```x OR y = TRUE```, a blue circle otherwise.\n",
    "\n",
    "<img src=\"img/or_perceptron1.png\"> </img> \n",
    "\n",
    "1. Can I realize this operation ```x OR y``` with a perceptron ?\n",
    "\n",
    "<img src=\"img/or_perceptron2.png\" style=\"display: none;\"> </img> \n",
    "\n",
    "<p style=\"color: white\"> Yes ! For example, take the weights $(a_1,a_2,a_0) = (1,1,-1)$. </p> \n",
    "\n",
    "2. In the same way, can I realize the operation ```x AND y``` with a perceptron ?\n",
    "\n",
    "<img src=\"img/and_perceptron1.png\" style=\"display: none;\"> </img> \n",
    "\n",
    "<p style=\"color: white\">Yes ! For example, take the weights $(a_1,a_2,a_0) = (1,1,-1.5)$. </p> \n",
    "\n",
    "3. In the same way, can I realize the operation ```x XOR y``` with a perceptron ?\n",
    "\n",
    "<img src=\"img/xor_perceptron.png\" style=\"display: none;\"> </img> \n",
    "\n",
    "<p style=\"color: white\"> No ! You cannot find a straight line that separates these two kind of points. </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is to know that the two sets of points are ... ... ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "In an $n$-dimensionnal Euclidian space, two sets of points $A$ and $B$ are linearly separable if an hyperplane can separate space : there exists $a_1,...,a_n,a_0$ such that for each $x \\in A$, $\\sum_{i=1}^n a_i x_i +a_0> 0$ and for each $x \\in B$, $\\sum_{i=1}^n a_i x_i + a_0 < 0$.     \n",
    "    An another way to say that is their respective convex hulls are disjoint.\n",
    " </div>\n",
    " \n",
    " <div class=\"alert alert-danger\" role=\"alert\">\t\n",
    "\n",
    "In an $n$-dimensionnal Euclidian space, two sets of points $A$ and $B$ are linearly separable if there exists a perceptron that takes value 1 on $A$ and 0 on $B$.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perceptron is a **linear classifier**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise \n",
    "\n",
    "Is it possible to realize the operation ```x OR y OR z``` with a perceptron ?\n",
    "\n",
    "<img src=\"img/or_or_perceptron.png\" style=\"display: none;\"> </img> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow, your perceptron is learning for the first time !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This learning rule is an example of supervised training, in which the learning rule is provided\n",
    "with a set of examples of proper perecptron behavior: a collection of $(x,t)$ where $x$ is an input and $t$ is a the corresponding target output. As each input is applied to the network, the network output is compared\n",
    "to the target. **The learning rule then adjusts the weights and biases\n",
    "of the perceptron in order to move the perceptron output closer to the target.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test problem\n",
    "These are 3  input/target pairs for our test problem :\n",
    "$$x_1 = (1,2) \\,;\\, t_1 = 1 \\qquad x_2 = (-1,2) \\,;\\, t_2 = 0 \\qquad x_3 = (0,-1) \\,;\\, t_3 = 0$$\n",
    "\n",
    "The perceptron for this problem should have two-inputs and one output. To\n",
    "simplify our development of the learning rule, we will begin with a network\n",
    "without a bias so that we are looking for two weights $a_1,a_2$. Activation function is Heaviside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[];t=[]\n",
    "x.append(np.array([1,2])) ; t.append(1)\n",
    "x.append(np.array(...)) ; t.append(...)\n",
    "x.append(np.array(...)) ; t.append(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing Learning Rules\n",
    "We set the weight vector $w = (a_1,a_2)$ to the following randomly generated values: $w = (1.0, -0.8)$. \n",
    "\n",
    "Then we execute the perceptron with the first input $x_1$ : output $y_1$ is equal to $0 \\neq t_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([1.0,-0.8])\n",
    "y = sum(w*x[0])\n",
    "print(y)\n",
    "y = H(y)\n",
    "print(y)\n",
    "y == t[0] #test if output y_1 is equal to t_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rule** : if $t=1$ and $y=0$ then $w_{new} := w_{old} + x$.\n",
    "\n",
    "Then we execute the perceptron with the second input $x_2$ and new weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ...\n",
    "y = ...\n",
    "y == t[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rule** : if $t=0$ and $y=1$ then $w_{new} := w_{old} - x$.\n",
    "\n",
    "Then we execute the perceptron with the second input $x_3$ and new weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply one of the previous rule :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if this perceptron network has correctly learned :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unfying Learning Rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This rule can be extended to train the bias by noting that a bias is simply\n",
    "a weight whose input is always 1.\n",
    "\n",
    "#### Exercise :\n",
    "Write a program that applies all the rules given above with different weights at start. Check the result. How many steps do we need to have a correct result ? Does it change if you change the weight at initialization or if you change the targets ? Comment yours results.\n",
    "\n",
    "Bonus : Represent with a 2d-graph the evolution of $w$ by plotting the corresponding linear classifyer.  \n",
    "\n",
    "Bonus ++ : prove that this learning rule converges towards the solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement\n",
    "\n",
    "\n",
    "A produce dealer has a warehouse that stores a variety of fruits and vegetables.\n",
    "When fruit is brought to the warehouse, various types of fruit may\n",
    "be mixed together. The dealer wants a machine that will sort the fruit according\n",
    "to type. There is a conveyer belt on which the fruit is loaded. This\n",
    "conveyer passes through a set of sensors, which measure three properties\n",
    "of the fruit: shape, texture and weight. These sensors are somewhat primitive.\n",
    "The shape sensor will output a 1 if the fruit is approximately round\n",
    "and a if it is more elliptical. The texture sensor will output a 1 if the surface\n",
    "of the fruit is smooth and a if it is rough. The weight sensor will\n",
    "output a 1 if the fruit is more than one pound and a if it is less than one\n",
    "pound.\n",
    "\n",
    "The three sensor outputs will then be input to a neural network. The purpose\n",
    "of the network is to decide which kind of fruit is on the conveyor, so\n",
    "that the fruit can be directed to the correct storage bin. To make the problem\n",
    "even simpler, let’s assume that there are only two kinds of fruit on the\n",
    "conveyor: apples and oranges.\n",
    "\n",
    "As each fruit passes through the sensors it can be represented by a threedimensional\n",
    "vector. The first element of the vector will represent shape,\n",
    "the second element will represent texture and the third element will represent\n",
    "weight: $$x = (shape, texture, weight)$$\n",
    "\n",
    "Therefore, a prototype orange would be represented by\n",
    "$$x_1 = (1,-1,-1)$$\n",
    "\n",
    "and a prototype apple would be represented by\n",
    "$$x_2 = (1,1,-1)$$\n",
    "\n",
    "The neural network will receive one three-dimensional input vector for\n",
    "each fruit on the conveyer and must make a decision as to whether the fruit\n",
    "is an orange or an apple ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
